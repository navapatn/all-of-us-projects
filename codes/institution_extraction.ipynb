{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR_blJYfMpUk",
        "outputId": "8674c22c-fcb0-485c-ad65-c8adfe7add48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classify the following institution: Prairie View A&M University. Is it an academic institution, company, or non-profit? Is it in the US or non-US, or is it unknown? If it is Non-US, what is the country? If in the USA, what state is it in? Within the USA, is it considered R1, R2, or neither, or is this unknown?\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "file_path = 'final_data_keywords_flags.csv'  # Adjust the path as necessary\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "data['Institutions'] = data['Institutions'].apply(\n",
        "    lambda x: set(ast.literal_eval(x)) if pd.notnull(x) else set()\n",
        ")\n",
        "\n",
        "prompts = []\n",
        "for institutions in data['Institutions']:\n",
        "    for institution in institutions:\n",
        "        prompt = f\"Classify the following institution: {institution}. \"\n",
        "        prompt += \"Is it an academic institution, company, or non-profit? \"\n",
        "        prompt += \"Is it in the US or non-US, or is it unknown? \"\n",
        "        prompt += \"If it is Non-US, what is the country? If in the USA, what state is it in? \"\n",
        "        prompt += \"Within the USA, is it considered R1, R2, or neither, or is this unknown?\"\n",
        "        prompts.append(prompt)\n",
        "\n",
        "print(prompts[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "file_path = 'final_data_keywords_flags.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "def generate_prompt(row):\n",
        "    institutions = row['Institutions']\n",
        "    institutions_list = set([inst.strip(\" '[]\") for inst in institutions.split(',')])\n",
        "    prompt = \"For the following institution(s), provide the classification, location (US or non-US), the state (if in the US) or country (if outside the US), and research classification (R1, R2, or neither). The response should be in a structured format suitable for conversion into a dictionary.\\n\\nInstitution(s):\\n\"\n",
        "    for institution in institutions_list:\n",
        "        prompt += f\"- {institution}\\n\"\n",
        "\n",
        "    prompt += \"\\nPlease format the response as a JSON object, containing the fields 'institution', 'classification', 'location', 'country_or_state', and 'research_classification'. For example:\\n\\n{\\n  \\\"institution\\\": \\\"[Name of the Institution]\\\",\\n  \\\"classification\\\": \\\"[academic/non-academic]\\\",\\n  \\\"location\\\": \\\"[US/non-US]\\\",\\n  \\\"country_or_state\\\": \\\"[if US, state name; if non-US, country name]\\\",\\n  \\\"research_classification\\\": \\\"[R1/R2/neither/don't know]\\\"\\n}\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "data['Prompt'] = data.apply(generate_prompt, axis=1)\n",
        "\n",
        "data.to_csv('prompts.csv', index=False)\n",
        "\n",
        "print(data['Prompt'][10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKrFxOKMOT9R",
        "outputId": "3c127949-dcd6-4e4e-9a91-d1ab764316af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For the following institution(s), provide the classification, location (US or non-US), the state (if in the US) or country (if outside the US), and research classification (R1, R2, or neither). The response should be in a structured format suitable for conversion into a dictionary.\n",
            "\n",
            "Institution(s):\n",
            "- Albert Einstein College of Medicine\n",
            "- Beth Israel Deaconess Medical Center\n",
            "\n",
            "Please format the response as a JSON object, containing the fields 'institution', 'classification', 'location', 'country_or_state', and 'research_classification'. For example:\n",
            "\n",
            "{\n",
            "  \"institution\": \"[Name of the Institution]\",\n",
            "  \"classification\": \"[academic/non-academic]\",\n",
            "  \"location\": \"[US/non-US]\",\n",
            "  \"country_or_state\": \"[if US, state name; if non-US, country name]\",\n",
            "  \"research_classification\": \"[R1/R2/neither/don't know]\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "openai.api_key = ''\n",
        "model = \"gpt-3.5-turbo-0125\"\n",
        "\n",
        "\n",
        "prompts_data = pd.read_csv('prompts.csv')\n",
        "\n",
        "\n",
        "results = []\n",
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "prompts_data = pd.read_csv('prompts.csv')\n",
        "\n",
        "results = []\n",
        "for index, row in prompts_data.iterrows():\n",
        "    prompt = row['Prompt']\n",
        "    messages = [{\"role\": \"system\", \"content\": \"Extract institutions information in JSON format. Follow the format in the prompt strictly\"},\n",
        "                {\"role\": \"user\", \"content\": prompt }]\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages\n",
        "        )\n",
        "        extracted_info = response.choices[0].message.content\n",
        "        results.append(extracted_info)\n",
        "\n",
        "        if index % 300 == 0:\n",
        "            responses_df = prompts_data.iloc[:index + 1]\n",
        "            responses_df['Response'] = results\n",
        "\n",
        "\n",
        "            responses_df.to_csv(f'responses_{index + 1}.csv', index=False)\n",
        "    except openai.OpenAIError as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        results.append(None)\n",
        "\n",
        "\n",
        "prompts_data['Response'] = results\n",
        "prompts_data.to_csv('responses.csv', index=False)\n",
        "prompts_data['Response'] = results\n",
        "prompts_data.to_csv('responses.csv', index=False)\n"
      ],
      "metadata": {
        "id": "ejHvWA7mQxNV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635c19ad-843b-4ca5-d164-6b71c83529c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-d95a33ea98d5>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  responses_df['Response'] = results\n",
            "<ipython-input-31-d95a33ea98d5>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  responses_df['Response'] = results\n",
            "<ipython-input-31-d95a33ea98d5>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  responses_df['Response'] = results\n",
            "<ipython-input-31-d95a33ea98d5>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  responses_df['Response'] = results\n",
            "<ipython-input-31-d95a33ea98d5>:45: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  responses_df['Response'] = results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "cleaned_responses = []\n",
        "for response in results:\n",
        "    cleaned_response = response.replace('\\n', '')\n",
        "    cleaned_responses.append(cleaned_response)\n",
        "\n",
        "cleaned_responses_json = [json.loads(response) for response in cleaned_responses]"
      ],
      "metadata": {
        "id": "kbHX0uvmSAGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def parse_json_response(response_str):\n",
        "    try:\n",
        "        corrected_str = response_str.replace('\"\"', '\"').strip('\"')\n",
        "        return json.loads(corrected_str)\n",
        "    except json.JSONDecodeError:\n",
        "        return None\n",
        "\n",
        "def process_data_v2(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    data['R1_flag'] = False\n",
        "    data['R2_flag'] = False\n",
        "    data['is_academic'] = False\n",
        "    data['country'] = None\n",
        "    data['state'] = None\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        response_json = parse_json_response(row['Response'])\n",
        "        if response_json:\n",
        "            countries = []\n",
        "            states = []\n",
        "\n",
        "            # Check if response contains multiple institutions\n",
        "            institutions = response_json.get('institutions', [response_json]) \\\n",
        "                if isinstance(response_json, dict) else response_json\n",
        "\n",
        "            for institution in institutions:\n",
        "                country = institution.get('location', '')\n",
        "                state = institution.get('country_or_state', '')\n",
        "                if country:\n",
        "                    countries.append(country)\n",
        "                if state:\n",
        "                    states.append(state)\n",
        "                if 'R1' in institution.get('research_classification', ''):\n",
        "                    data.at[index, 'R1_flag'] = True\n",
        "                if 'R2' in institution.get('research_classification', ''):\n",
        "                    data.at[index, 'R2_flag'] = True\n",
        "                if institution.get('classification', '') == 'academic':\n",
        "                    data.at[index, 'is_academic'] = True\n",
        "            data.at[index, 'country'] = ', '.join(set(countries))\n",
        "            data.at[index, 'state'] = ', '.join(set(states))\n",
        "\n",
        "    return data\n",
        "\n",
        "processed_data_v2 = process_data_v2(file_path)\n",
        "\n",
        "processed_data_v2.head(30)\n",
        "processed_data_v2.to_csv('processed_responses.csv', index=False)"
      ],
      "metadata": {
        "id": "M41XmskpkGOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "def parse_json_response(response_str):\n",
        "    corrected_str = response_str.replace('\"{', '{').replace('}\"', '}').replace('\"\"', '\"').strip('\"')\n",
        "    try:\n",
        "        return json.loads(corrected_str)\n",
        "    except json.JSONDecodeError:\n",
        "        return None\n",
        "\n",
        "def process_data(file_path):\n",
        "    data = pd.read_csv(file_path)\n",
        "    data['R1_flag'] = False\n",
        "    data['R2_flag'] = False\n",
        "    data['is_academic'] = False\n",
        "    data['country'] = None\n",
        "    data['state'] = None\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        response_json = parse_json_response(row['Response'])\n",
        "        if response_json:\n",
        "            institutions = [response_json] if isinstance(response_json, dict) else response_json\n",
        "\n",
        "            countries = set()\n",
        "            states = set()\n",
        "            for institution in institutions:\n",
        "                country = institution.get('location', '')\n",
        "                state = institution.get('country_or_state', '')\n",
        "                if country:\n",
        "                    countries.add(country)\n",
        "                if state:\n",
        "                    states.add(state)\n",
        "                if 'R1' in institution.get('research_classification', ''):\n",
        "                    data.at[index, 'R1_flag'] = True\n",
        "                if 'R2' in institution.get('research_classification', ''):\n",
        "                    data.at[index, 'R2_flag'] = True\n",
        "                if institution.get('classification', '') == 'academic':\n",
        "                    data.at[index, 'is_academic'] = True\n",
        "\n",
        "            data.at[index, 'country'] = ', '.join(countries)\n",
        "            data.at[index, 'state'] = ', '.join(states)\n",
        "\n",
        "    return data\n",
        "\n",
        "file_path = 'responses.csv'\n",
        "processed_data = process_data(file_path)\n",
        "processed_data.to_csv('processed_responses.csv', index=False)\n"
      ],
      "metadata": {
        "id": "CGQVvz1xrGFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('processed_responses.csv')\n",
        "\n",
        "r1_count = data['R1_flag'].sum()\n",
        "r2_count = data['R2_flag'].sum()\n",
        "\n",
        "print(f\"Number of R1 institutions: {r1_count}\")\n",
        "print(f\"Number of R2 institutions: {r2_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQs31i3D3goW",
        "outputId": "d8f84bfb-6c84-4965-d210-68c4f4f544dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of R1 institutions: 941\n",
            "Number of R2 institutions: 236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "from collections import Counter\n",
        "\n",
        "data = pd.read_csv('processed_responses.csv')\n",
        "\n",
        "data['UMLS_Codes'] = data['UMLS_Codes'].apply(lambda x: ast.literal_eval(x))\n",
        "data['Keywords'] = data['Keywords'].apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "umls_to_keyword = {}\n",
        "for keywords, codes in zip(data['Keywords'], data['UMLS_Codes']):\n",
        "    for keyword, code in zip(keywords, codes):\n",
        "        if code not in umls_to_keyword:\n",
        "            umls_to_keyword[code] = keyword.lower()\n",
        "\n",
        "data['Mapped_Keywords'] = data['UMLS_Codes'].apply(lambda codes: [umls_to_keyword[code] for code in codes])\n",
        "grouped_r1 = data[data['R1_flag']].groupby('Category')\n",
        "grouped_r2 = data[data['R2_flag']].groupby('Category')\n",
        "\n",
        "def calculate_keyword_frequencies(grouped_df):\n",
        "    frequencies = {}\n",
        "    for category, group in grouped_df:\n",
        "        all_keywords = [keyword for sublist in group['Mapped_Keywords'] for keyword in sublist]\n",
        "        frequencies[category] = pd.Series(all_keywords).value_counts()\n",
        "    return frequencies\n",
        "\n",
        "r1_keywords_freq = calculate_keyword_frequencies(grouped_r1)\n",
        "r2_keywords_freq = calculate_keyword_frequencies(grouped_r2)\n",
        "\n",
        "\n",
        "print(\"R1 Institutions:\")\n",
        "for category, freq in r1_keywords_freq.items():\n",
        "    print(f\"Category '{category}':\")\n",
        "    print(freq.head(10))\n",
        "    print()\n",
        "\n",
        "print(\"R2 Institutions:\")\n",
        "for category, freq in r2_keywords_freq.items():\n",
        "    print(f\"Category '{category}':\")\n",
        "    print(freq.head(10))\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "r1_df_list = [{'Category': category, 'Keyword': k, 'Frequency': v}\n",
        "              for category, freqs in r1_keywords_freq.items()\n",
        "              for k, v in freqs.head(10).items()]\n",
        "r1_results_df = pd.DataFrame(r1_df_list)\n",
        "\n",
        "\n",
        "r1_results_df.to_csv('r1_keyword_frequencies.csv', index=False)\n",
        "\n",
        "\n",
        "r2_df_list = [{'Category': category, 'Keyword': k, 'Frequency': v}\n",
        "              for category, freqs in r2_keywords_freq.items()\n",
        "              for k, v in freqs.head(10).items()]\n",
        "r2_results_df = pd.DataFrame(r2_df_list)\n",
        "\n",
        "\n",
        "r2_results_df.to_csv('r2_keyword_frequencies.csv', index=False)\n"
      ],
      "metadata": {
        "id": "uYjtrV3U5LMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2152d575-2528-4a86-d779-d27726662146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1 Institutions:\n",
            "Category 'asthma-pollution':\n",
            "asthma treatment         53\n",
            "lung diseases            14\n",
            "air pollution            13\n",
            "logistic regression       8\n",
            "atopic dermatitis         8\n",
            "comorbidities             8\n",
            "allergic rhinitis         8\n",
            "environmental factors     5\n",
            "risk factors              5\n",
            "health disparities        5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category 'cardiovascular-with':\n",
            "cardiovascular disease           189\n",
            "heart failure                     31\n",
            "risk factors                      30\n",
            "social determinants of health     29\n",
            "hypertension                      29\n",
            "coronary heart disease            21\n",
            "type 2 diabetes                   21\n",
            "common diseases                   19\n",
            "health disparities                18\n",
            "genetic variants                  18\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category 'dementias-alzheimers':\n",
            "american population                  106\n",
            "adolescent symptoms of depression     39\n",
            "hypertension                          14\n",
            "risk factors                          14\n",
            "logistic regression                    9\n",
            "common diseases                        8\n",
            "social determinants of health          8\n",
            "environmental factors                  8\n",
            "cardiovascular disease                 8\n",
            "genetic variants                       7\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category 'diabetes-with':\n",
            "type 2 diabetes           133\n",
            "common diseases           105\n",
            "type 1 diabetes            38\n",
            "hypertension               31\n",
            "cardiovascular disease     30\n",
            "obesity                    29\n",
            "health disparities         24\n",
            "risk factors               23\n",
            "genetic variants           22\n",
            "comorbidities              19\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category 'mental-health':\n",
            "major depression                 37\n",
            "mental health                    28\n",
            "social determinants of health    26\n",
            "anxiety                          24\n",
            "mental disorders                 22\n",
            "health disparities               18\n",
            "covid-19                         15\n",
            "mental health disorders          12\n",
            "sociodemographic factors         12\n",
            "mental health outcomes           11\n",
            "Name: count, dtype: int64\n",
            "\n",
            "R2 Institutions:\n",
            "Category 'asthma-pollution':\n",
            "asthma treatment                     8\n",
            "health disparities                   2\n",
            "asthma health disparities            1\n",
            "major depression                     1\n",
            "guideline-appropriate medications    1\n",
            "public health interventions          1\n",
            "treatment disparities                1\n",
            "logistic regression                  1\n",
            "pediatric asthma                     1\n",
            "provider adherence                   1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category 'cardiovascular-with':\n",
            "cardiovascular disease           35\n",
            "heart failure                    13\n",
            "social determinants of health    12\n",
            "hypertension                     11\n",
            "obesity                           9\n",
            "common diseases                   6\n",
            "physical activity                 6\n",
            "type 2 diabetes                   6\n",
            "risk factors                      6\n",
            "cancer patients                   6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category 'dementias-alzheimers':\n",
            "american population                  23\n",
            "adolescent symptoms of depression    11\n",
            "personalized medicine                 2\n",
            "comorbidities                         2\n",
            "missing at random generator           2\n",
            "anticipated findings                  2\n",
            "scientific questions                  2\n",
            "research                              2\n",
            "health disparities                    2\n",
            "us population                         2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category 'diabetes-with':\n",
            "common diseases                  34\n",
            "type 2 diabetes                  33\n",
            "obesity                          15\n",
            "hypertension                     12\n",
            "health disparities               11\n",
            "type 1 diabetes                  10\n",
            "cardiovascular disease            9\n",
            "genetic variants                  8\n",
            "biomedical research               6\n",
            "social determinants of health     6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Category 'mental-health':\n",
            "sociodemographic factors         10\n",
            "social determinants of health     8\n",
            "anxiety                           7\n",
            "major depression                  7\n",
            "mental disorders                  7\n",
            "mental health disorders           6\n",
            "health disparities                6\n",
            "covid-19                          5\n",
            "data analysis                     4\n",
            "genomic data                      3\n",
            "Name: count, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# Load the data\n",
        "file_path = 'processed_responses.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Convert string representation of list in 'Institutions' to actual list\n",
        "data['Institutions'] = data['Institutions'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
        "\n",
        "# Flatten the list of institutions to get a single list with all institutions\n",
        "all_institutions = [institution for sublist in data['Institutions'] for institution in sublist]\n",
        "\n",
        "# Calculate the number of unique institutions across all data\n",
        "unique_institutions = set(all_institutions)\n",
        "total_unique_institutions = len(unique_institutions)\n",
        "\n",
        "# Group by 'Category' to find unique institutions for each category\n",
        "category_institutions = data.explode('Institutions').groupby('Category')['Institutions'].nunique()\n",
        "\n",
        "# Analyze multi-institutional teams and R2_flag\n",
        "multi_institutional_data = data[data['Is Multi-Institutional'] == True]\n",
        "multi_institutional_with_R2 = multi_institutional_data[multi_institutional_data['R2_flag'] == True ]\n",
        "percentage_multi_institutional_with_R2 = (len(multi_institutional_with_R2) / len(multi_institutional_data) * 100\n",
        "                                          if len(multi_institutional_data) > 0 else 0)\n",
        "\n",
        "print(f\"Total unique institutions: {total_unique_institutions}\")\n",
        "print(f\"Unique institutions by category: {category_institutions.to_dict()}\")\n",
        "print(f\"Percentage of multi-institutional teams involving at least one R2 institution: {percentage_multi_institutional_with_R2}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgxMPcf15PjM",
        "outputId": "88dfbf85-4596-422b-9d41-22d264509134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique institutions: 283\n",
            "Unique institutions by category: {'asthma-pollution': 61, 'cardiovascular-with': 153, 'dementias-alzheimers': 88, 'diabetes-with': 176, 'mental-health': 140}\n",
            "Percentage of multi-institutional teams involving at least one R2 institution: 33.12883435582822%\n"
          ]
        }
      ]
    }
  ]
}